{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to spam model\n",
    "* 89% accuracy--> we predict incorrectly about one time out of tem\n",
    "* Is it a good standard?\n",
    "* example of class imbalance where one kind of outcome is much more common than the other, skewing the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance\n",
    "\n",
    "In ideal world, training data would contain eq number of all possible outcomes so you can find what features indivate a propensity for a certain category of outcome. BUT this is RARE\n",
    "\n",
    "\n",
    "Small imbalance in outcome classes does not tend to make much difference. \n",
    "Large Class imbalance can hugely affect your model. \n",
    "* This is because when one class makes up a large portion of the data, it can be pretty successful for a model to simply choose the dominant class every time. \n",
    "* a rare event will have to have distinguishing traits in order to accurately predict it. \n",
    "* if those traits that tend to define a rare event are often seen in the dominant class as well, then model is going to predict the dominant class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Performance\n",
    "\n",
    "How to come up with a good baseline for performance; \n",
    "* one of the simplest way--> through Dominant class rate\n",
    "    * dominant class = most common outcome for our target variable. \n",
    "    * simplest version of a classifier is to just always predict that the reslt will be the most liekly outcome\n",
    "* useful to think about your model's success rate relative to that dominant class rate. \n",
    "    * if you predict something correctly 99% of the time, but its 99% dominated by a single class, that isnt an impressive prediction. \n",
    "* in the case of spam filter: only 13.4% of trials were spam. \n",
    "    * model that always predicted ham would have a 86.6% accuracy rate, but be completely useless for its intended purpose of filtering out spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with class imbalance\n",
    "\n",
    "Few things to do to deal with this problem: \n",
    "* Easiest is to ignore it. If we only care about the abs accuracty of the model and our samp is representative of the pop we aim to predict, this can be reasonable strategy\n",
    "* CHange sampling. \n",
    "* probability outputs.\n",
    "* Create cost functions for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
